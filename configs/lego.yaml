seed: 4
data:
  path: '/mnt/d/project/mipnerf-pytorch/lego'
  name: 'multicam'
train:
  batch_size: 32
  batch_type: 'all_images'  # single_image: inputs a full image; all_images: inputs batch_size rays sampled from different image
  num_work: 0
  randomized: True
  white_bkgd: True
  stats_print_interval: 10
val:
  batch_size: 1
  batch_type: 'single_image'  # For "single_image", the batch must set to 1
  num_work: 0
  randomized: False
  white_bkgd: True
  epoch_interval: 1
  chunk_size: 1024  # The amount of input rays in a forward propagation
  sample_num: 4  # Total number of images verified during once validation
nerf:
  num_samples: 128  # The number of samples per level.
  num_levels: 2  # The number of sampling levels.
  resample_padding: 0.01  # Dirichlet/alpha "padding" on the histogram.
  stop_resample_grad: True  # If True, don't backprop across levels')
  use_viewdirs: True  # If True, use view directions as a condition.
  disparity: False  # If True, sample linearly in disparity, not in depth.
  ray_shape: 'cone'  # The shape of cast rays ('cone' or 'cylinder').
  min_deg_point: 0  # Min degree of positional encoding for 3D points.
  max_deg_point: 16  # Max degree of positional encoding for 3D points.
  deg_view: 4  # Degree of positional encoding for viewdirs.
  density_activation: 'softplus'  # Density activation.
  density_noise: 0.  # Standard deviation of noise added to raw density.
  density_bias: -1.  # The shift added to raw densities pre-activation.
  rgb_activation: 'sigmoid'  # The RGB activation.
  rgb_padding: 0.001  # Padding added to the RGB outputs.
  disable_integration: False  # If True, use PE instead of IPE.
  append_identity: Ture  # If True, append original view direction features
  mlp:
    feature_dim: 96
    net_depth: 8  # The depth of the first part of MLP.
    net_width: 256  # The width of the first part of MLP.
    net_depth_condition: 1  # The depth of the second part of MLP.
    net_width_condition: 128  # The width of the second part of MLP.
    net_activation: 'relu'  # The activation function.
    skip_index: 4  # Add a skip connection to the output of every N layers.
    num_rgb_channels: 3  # The number of RGB channels.
    num_density_channels: 1  # The number of density channels.
optimizer:
  lr_init: 5e-4  # The initial learning rate.
  lr_final: 5e-6  # The final learning rate.
  lr_delay_steps: 2500  # The number of "warmup" learning steps.
  lr_delay_mult: 0.01  # How much sever the "warmup" should be.
  max_steps: 100
loss:
  disable_multiscale_loss: False
  coarse_loss_mult: 0.1
visualization:
  history_size: 10
  visdom: False
  visdom_server: 'localhost'
  visdom_port: 8097
  visdom_env: 'nerf_pytorch3d'
  val_image_path: 'val_image'
checkpoint:
  path: 'checkpoints'
  name: 'lego.pth'
  epoch_interval: 1
hydra:
  run:
    dir: './outputs/lego/${now:%Y-%m-%d_%H-%M-%S}'